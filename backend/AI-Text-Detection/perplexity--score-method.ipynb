{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-25T11:21:37.910471Z",
     "iopub.status.busy": "2023-07-25T11:21:37.909954Z",
     "iopub.status.idle": "2023-07-25T11:21:53.415827Z",
     "shell.execute_reply": "2023-07-25T11:21:53.414814Z",
     "shell.execute_reply.started": "2023-07-25T11:21:37.910434Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from datasets import Dataset, load_dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T11:21:53.424123Z",
     "iopub.status.busy": "2023-07-25T11:21:53.421105Z",
     "iopub.status.idle": "2023-07-25T11:22:29.112809Z",
     "shell.execute_reply": "2023-07-25T11:22:29.111763Z",
     "shell.execute_reply.started": "2023-07-25T11:21:53.424084Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_id = \"gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:20.363469Z",
     "iopub.status.busy": "2023-07-24T06:16:20.363091Z",
     "iopub.status.idle": "2023-07-24T06:16:30.617289Z",
     "shell.execute_reply": "2023-07-24T06:16:30.616335Z",
     "shell.execute_reply.started": "2023-07-24T06:16:20.363436Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"rajendrabaskota/hc3-wiki-intro-dataset\", split=\"train\")\n",
    "test_dataset = load_dataset(\"rajendrabaskota/hc3-wiki-intro-dataset\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T17:58:26.800781Z",
     "iopub.status.busy": "2023-07-20T17:58:26.800422Z",
     "iopub.status.idle": "2023-07-20T17:58:26.807832Z",
     "shell.execute_reply": "2023-07-20T17:58:26.806894Z",
     "shell.execute_reply.started": "2023-07-20T17:58:26.800729Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Function to Calculate Perplexity Score of Given Text\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T11:22:29.115694Z",
     "iopub.status.busy": "2023-07-25T11:22:29.115300Z",
     "iopub.status.idle": "2023-07-25T11:22:29.125274Z",
     "shell.execute_reply": "2023-07-25T11:22:29.124105Z",
     "shell.execute_reply.started": "2023-07-25T11:22:29.115660Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_perplexity_score(text):\n",
    "    max_length = 64\n",
    "    stride = 32\n",
    "    # obtaining the encodings from text\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "    # list for storing negative log likelihood of each window\n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    \n",
    "    for begin_loc in range(0, seq_len, stride):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs.loss\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    perplexity = torch.exp(torch.stack(nlls).mean()) # taking mean and performing exponentiation\n",
    "    return float(perplexity.cpu().detach().numpy()) # returning perplexity score as a floating point number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calculate Mean Length\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T17:58:52.177251Z",
     "iopub.status.busy": "2023-07-20T17:58:52.176889Z",
     "iopub.status.idle": "2023-07-20T17:58:57.043532Z",
     "shell.execute_reply": "2023-07-20T17:58:57.042532Z",
     "shell.execute_reply.started": "2023-07-20T17:58:52.177222Z"
    }
   },
   "outputs": [],
   "source": [
    "text_count = 0\n",
    "length = 0\n",
    "text_length_list = []\n",
    "texts = train_dataset['text']\n",
    "text_count = 0\n",
    "\n",
    "for i in tqdm(range(len(texts))):\n",
    "    current_text = texts[i]\n",
    "    current_length = len(current_text.split())\n",
    "    length += current_length\n",
    "    text_length_list.append(current_length)\n",
    "    text_count += 1\n",
    "    \n",
    "q3 = sorted(text_length_list)[int(0.75 * len(text_length_list))]\n",
    "mean_length = length / text_count\n",
    "\n",
    "print(\"Q3:\", q3)\n",
    "print(\"mean_length:\", mean_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calculate Perplexity\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T18:22:57.302063Z",
     "iopub.status.busy": "2023-07-15T18:22:57.301705Z",
     "iopub.status.idle": "2023-07-16T00:22:56.170536Z",
     "shell.execute_reply": "2023-07-16T00:22:56.169571Z",
     "shell.execute_reply.started": "2023-07-15T18:22:57.302028Z"
    }
   },
   "outputs": [],
   "source": [
    "min_index = 240_000\n",
    "max_index = len(train_dataset['text'])\n",
    "\n",
    "\n",
    "total = max_index - min_index\n",
    "perplexity_score_list = []\n",
    "\n",
    "train_dataset_texts = train_dataset['text']\n",
    "\n",
    "for i in tqdm(range(total)):\n",
    "    current_text = train_dataset_texts[min_index + i]\n",
    "    perplexity = compute_perplexity_score(current_text)\n",
    "    perplexity_score_list.append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T00:22:56.172971Z",
     "iopub.status.busy": "2023-07-16T00:22:56.172265Z",
     "iopub.status.idle": "2023-07-16T00:22:56.179721Z",
     "shell.execute_reply": "2023-07-16T00:22:56.178812Z",
     "shell.execute_reply.started": "2023-07-16T00:22:56.172935Z"
    }
   },
   "outputs": [],
   "source": [
    "len(perplexity_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T17:59:01.845232Z",
     "iopub.status.busy": "2023-07-20T17:59:01.844230Z",
     "iopub.status.idle": "2023-07-20T19:07:46.454356Z",
     "shell.execute_reply": "2023-07-20T19:07:46.453395Z",
     "shell.execute_reply.started": "2023-07-20T17:59:01.845184Z"
    }
   },
   "outputs": [],
   "source": [
    "test_perplexity_score_list = []\n",
    "\n",
    "test_dataset_texts = test_dataset['text']\n",
    "\n",
    "for i in tqdm(range(len(test_dataset_texts))):\n",
    "    current_text = test_dataset_texts[i]\n",
    "    perplexity = compute_perplexity_score(current_text)\n",
    "    test_perplexity_score_list.append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:07:46.457258Z",
     "iopub.status.busy": "2023-07-20T19:07:46.456435Z",
     "iopub.status.idle": "2023-07-20T19:07:46.464396Z",
     "shell.execute_reply": "2023-07-20T19:07:46.463346Z",
     "shell.execute_reply.started": "2023-07-20T19:07:46.457221Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_perplexity_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:07:46.466312Z",
     "iopub.status.busy": "2023-07-20T19:07:46.465926Z",
     "iopub.status.idle": "2023-07-20T19:07:46.544607Z",
     "shell.execute_reply": "2023-07-20T19:07:46.543592Z",
     "shell.execute_reply.started": "2023-07-20T19:07:46.466279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding perplexity score to test dataset\n",
    "test_dataset = test_dataset.add_column(\"perplexity\", test_perplexity_score_list)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:08:38.250760Z",
     "iopub.status.busy": "2023-07-20T19:08:38.249611Z",
     "iopub.status.idle": "2023-07-20T19:08:56.511132Z",
     "shell.execute_reply": "2023-07-20T19:08:56.509679Z",
     "shell.execute_reply.started": "2023-07-20T19:08:38.250687Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U datasets huggingface-hub\n",
    "# !huggingface-cli login --token <your_token>\n",
    "\n",
    "# # Pushing test dataset to hub\n",
    "# test_dataset.push_to_hub(\"hc3-and-gpt-wiki-intro-with-perplexity\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save perplexity score and get download link\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:10:10.773505Z",
     "iopub.status.busy": "2023-07-20T19:10:10.773101Z",
     "iopub.status.idle": "2023-07-20T19:10:10.787379Z",
     "shell.execute_reply": "2023-07-20T19:10:10.785865Z",
     "shell.execute_reply.started": "2023-07-20T19:10:10.773473Z"
    }
   },
   "outputs": [],
   "source": [
    "perplexity_score_dataframe = pd.DataFrame.from_dict({\"perplexity\": perplexity_score_list})\n",
    "# perplexity_score_dataframe = pd.DataFrame.from_dict({\"perplexity\": test_perplexity_score_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:10:14.366148Z",
     "iopub.status.busy": "2023-07-20T19:10:14.364947Z",
     "iopub.status.idle": "2023-07-20T19:10:14.387751Z",
     "shell.execute_reply": "2023-07-20T19:10:14.386609Z",
     "shell.execute_reply.started": "2023-07-20T19:10:14.366102Z"
    }
   },
   "outputs": [],
   "source": [
    "perplexity_score_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:10:43.570798Z",
     "iopub.status.busy": "2023-07-20T19:10:43.568371Z",
     "iopub.status.idle": "2023-07-20T19:10:43.660481Z",
     "shell.execute_reply": "2023-07-20T19:10:43.659536Z",
     "shell.execute_reply.started": "2023-07-20T19:10:43.570762Z"
    }
   },
   "outputs": [],
   "source": [
    "perplexity_score_dataframe.to_csv(f\"perplexity_score_{min_index}-{max_index}.csv.gz\", compression=\"gzip\", index=False)\n",
    "# perplexity_score_dataframe.to_csv(f\"test_perplexity_score.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T19:10:56.612836Z",
     "iopub.status.busy": "2023-07-20T19:10:56.612435Z",
     "iopub.status.idle": "2023-07-20T19:10:56.619514Z",
     "shell.execute_reply": "2023-07-20T19:10:56.618552Z",
     "shell.execute_reply.started": "2023-07-20T19:10:56.612802Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(f\"perplexity_score_{min_index}-{max_index}.csv.gz\")\n",
    "# FileLink(f\"test_perplexity_score.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T22:03:18.772444Z",
     "iopub.status.busy": "2023-07-24T22:03:18.771460Z",
     "iopub.status.idle": "2023-07-24T22:03:18.779469Z",
     "shell.execute_reply": "2023-07-24T22:03:18.778288Z",
     "shell.execute_reply.started": "2023-07-24T22:03:18.772401Z"
    }
   },
   "outputs": [],
   "source": [
    "def application():\n",
    "    THRESHOLD = 12.80\n",
    "    text = str(input(\"\\n\\nEnter text to check:\\n\\n\"))\n",
    "    ppl_score = compute_perplexity_score(text)\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\">   Perplexity Score:\", ppl_score)\n",
    "    print(\">   Threshold: \", THRESHOLD)\n",
    "\n",
    "    if(ppl_score >= THRESHOLD):\n",
    "        print(\">   The given text is HUMAN written.\")\n",
    "    else:\n",
    "        print(\">   The given text is AI generated.\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Perplexity Score Method\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T22:17:13.072234Z",
     "iopub.status.busy": "2023-07-24T22:17:13.071865Z",
     "iopub.status.idle": "2023-07-24T22:17:35.165810Z",
     "shell.execute_reply": "2023-07-24T22:17:35.164681Z",
     "shell.execute_reply.started": "2023-07-24T22:17:13.072204Z"
    }
   },
   "outputs": [],
   "source": [
    "application()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
