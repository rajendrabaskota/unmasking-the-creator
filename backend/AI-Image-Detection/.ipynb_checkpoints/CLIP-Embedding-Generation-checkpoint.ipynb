{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U datasets huggingface-hub\n",
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the notebook before proceeding further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:36.538970Z",
     "iopub.status.busy": "2024-01-07T11:56:36.538608Z",
     "iopub.status.idle": "2024-01-07T11:56:38.221743Z",
     "shell.execute_reply": "2024-01-07T11:56:38.220670Z",
     "shell.execute_reply.started": "2024-01-07T11:56:36.538935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93f8948eae44c49afcc480b6c58c90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('<your_token>')\"\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:20:54.829013Z",
     "iopub.status.busy": "2024-01-12T16:20:54.828272Z",
     "iopub.status.idle": "2024-01-12T16:21:00.734478Z",
     "shell.execute_reply": "2024-01-12T16:21:00.733557Z",
     "shell.execute_reply.started": "2024-01-12T16:20:54.828972Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating DataFrame Object for Storing All Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:51.419105Z",
     "iopub.status.busy": "2024-01-07T11:56:51.418657Z",
     "iopub.status.idle": "2024-01-07T11:56:51.423699Z",
     "shell.execute_reply": "2024-01-07T11:56:51.422726Z",
     "shell.execute_reply.started": "2024-01-07T11:56:51.419078Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_image_names(path):\n",
    "    return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:51.425720Z",
     "iopub.status.busy": "2024-01-07T11:56:51.425040Z",
     "iopub.status.idle": "2024-01-07T11:56:51.438184Z",
     "shell.execute_reply": "2024-01-07T11:56:51.437272Z",
     "shell.execute_reply.started": "2024-01-07T11:56:51.425683Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_df(df, path, images):\n",
    "    for img_type, img_names in images.items():\n",
    "        new_row = []\n",
    "        new_row = [[path + img_type + '/' + img_name, int(img_type[0])] for img_name in img_names]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row, columns=[\"file_path\", \"label\"])], ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:54.010537Z",
     "iopub.status.busy": "2024-01-07T11:56:54.010171Z",
     "iopub.status.idle": "2024-01-07T11:56:55.175876Z",
     "shell.execute_reply": "2024-01-07T11:56:55.175050Z",
     "shell.execute_reply.started": "2024-01-07T11:56:54.010507Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"file_path\": [],\n",
    "    \"label\": []\n",
    "}, dtype=int)\n",
    "\n",
    "base_dir = \"/kaggle/input/diffusion-datasets/diffusion_datasets/\"\n",
    "folders = os.listdir(base_dir)\n",
    "for folder in folders:\n",
    "    if collections.Counter(os.listdir(base_dir + folder)) == collections.Counter(['1_fake']):\n",
    "        fake_images = fetch_image_names(base_dir + folder+'/'+'1_fake')\n",
    "        path = folder + '/'\n",
    "        images = {'1_fake': fake_images}\n",
    "        df = append_df(df, path, images)\n",
    "    else:\n",
    "        real_images = fetch_image_names(base_dir + folder+'/'+'0_real')\n",
    "        path = folder + '/'\n",
    "        images = {'0_real': real_images}\n",
    "        df = append_df(df, path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Generating Feature Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:33.468870Z",
     "iopub.status.busy": "2024-01-07T11:57:33.468515Z",
     "iopub.status.idle": "2024-01-07T11:57:52.526401Z",
     "shell.execute_reply": "2024-01-07T11:57:52.525230Z",
     "shell.execute_reply.started": "2024-01-07T11:57:33.468842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b985c3adc894eca96de1b7abaadb711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a87e97dcca41c29f8b205586c49326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2090e2b9e584911bfb65ec58398470d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a38a38ac49457cbcf6d8b80922b556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8fb6e8c02e419a8d0fb9c48b696bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648c17e8cba2472bbbfa6e76c65c7b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee33ecce3a94f4eae1f9a88cc17d437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d73b4f8c724b36a7acc2c5978349f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(\"cuda\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:52.528787Z",
     "iopub.status.busy": "2024-01-07T11:57:52.528153Z",
     "iopub.status.idle": "2024-01-07T11:57:52.539046Z",
     "shell.execute_reply": "2024-01-07T11:57:52.537781Z",
     "shell.execute_reply.started": "2024-01-07T11:57:52.528756Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(base_dir + self.x.iloc[idx]['file_path']).resize((256, 256))\n",
    "        image = convert_tensor(image)\n",
    "        \n",
    "        if not image.shape[0] == 3:\n",
    "            print(f\"yes at index {idx}\")\n",
    "            image = image.repeat(3, 1, 1)\n",
    "            \n",
    "        return idx, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:52.540538Z",
     "iopub.status.busy": "2024-01-07T11:57:52.540220Z",
     "iopub.status.idle": "2024-01-07T11:57:56.821295Z",
     "shell.execute_reply": "2024-01-07T11:57:56.820083Z",
     "shell.execute_reply.started": "2024-01-07T11:57:52.540513Z"
    }
   },
   "outputs": [],
   "source": [
    "df['img_embed'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:56.824605Z",
     "iopub.status.busy": "2024-01-07T11:57:56.824003Z",
     "iopub.status.idle": "2024-01-07T11:57:56.906548Z",
     "shell.execute_reply": "2024-01-07T11:57:56.905645Z",
     "shell.execute_reply.started": "2024-01-07T11:57:56.824576Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset=CustomDataset(df),\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_index = 0\n",
    "# end_index = start_index + batch_size\n",
    "\n",
    "for idx, data in tqdm(dataloader):\n",
    "    images = data*255\n",
    "    inputs = processor(text='nothing', images=images, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "    outputs = model(**inputs)\n",
    "    outputs = outputs['image_embeds'].tolist()\n",
    "#     outputs = [str(obj) for obj in outputs]\n",
    "    idx = idx.tolist()\n",
    "    df['img_embed'].iloc[idx] = outputs\n",
    "    \n",
    "#     df.loc[idx, 'img_embed'] = outputs\n",
    "#     start_index = end_index\n",
    "#     end_index = start_index+batch_size if start_index+batch_size <= len(df) else len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T12:12:23.764852Z",
     "iopub.status.busy": "2024-01-07T12:12:23.764117Z",
     "iopub.status.idle": "2024-01-07T12:12:24.993071Z",
     "shell.execute_reply": "2024-01-07T12:12:24.992119Z",
     "shell.execute_reply.started": "2024-01-07T12:12:23.764820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file_path', 'label', 'img_embed'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T12:12:36.167059Z",
     "iopub.status.busy": "2024-01-07T12:12:36.164852Z",
     "iopub.status.idle": "2024-01-07T12:12:43.183077Z",
     "shell.execute_reply": "2024-01-07T12:12:43.182107Z",
     "shell.execute_reply.started": "2024-01-07T12:12:36.167020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39d2f537fd6485eb373368108c8986b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3b4fb61514407d91dfd6128ccf2bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/rajendrabaskota/diffusion-test-dataset/commit/6353fa65e037fd3aa33039821d7fa4ae602e3bad', commit_message='Upload dataset', commit_description='', oid='6353fa65e037fd3aa33039821d7fa4ae602e3bad', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"rajendrabaskota/diffusion-test-dataset\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_all = load_dataset(\"rajendrabaskota/gans-test-dataset\")\n",
    "test_dataset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(test_dataset_all.keys())\n",
    "test_dataset = concatenate_datasets([test_dataset_all[split] for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.push_to_hub(\"rajendrabaskota/gan-test-dataset\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Storing and Pushing to Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[60000:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_parquet('dataset-gans-60000-70000.parquet')  # If your file name isn't dataset.parquet replace it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"added test data with image embeddings\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli lfs-enable-largefiles /kaggle/working/gans-test-dataset-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets init -p /kaggle/working/mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Data to be written\n",
    "dictionary = {\"username\":\"pistukispo\", \"key\":\"398889364b2ed7a796587383380d0f3e\"}\n",
    "\n",
    "# Serializing json\n",
    "json_object = json.dumps(dictionary, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as outfile:\n",
    "\toutfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "with open('/kaggle/working/mydata/dataset-metadata.json', 'r') as openfile:\n",
    "    # Reading from json file\n",
    "    json_object = json.load(openfile)\n",
    " \n",
    "print(json_object)\n",
    "print(type(json_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object['title'] = \"gans-test-dataset-last\"\n",
    "json_object['id'] = \"pistukispo/gans-test-dataset-last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(json_object, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"/kaggle/working/mydata/dataset-metadata.json\", \"w\") as outfile:\n",
    "\toutfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets create -p /kaggle/working/mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'a': [1,2,3],\n",
    "                    'b': [4,5,6],\n",
    "                    'c': [7,8,9]})\n",
    "temp.to_csv('temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets version -p /kaggle/working/mydata -m \"Your message here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"data-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "resnet_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).to(\"cuda\")\n",
    "convert_tensor = transforms.ToTensor()\n",
    "image = Image.open(\"/kaggle/input/few-ai-real-images/dalle.png\").resize((224, 224))\n",
    "image = convert_tensor(image)\n",
    "\n",
    "resnet_model.eval()\n",
    "resnet_model.training # to verify if the model is in eval mode\n",
    "resnet_model(image.unsqueeze(dim=0)) # not necessary to unsqueeze when sent in batches\n",
    "\n",
    "#optional\n",
    "for param in resnet_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4267723,
     "sourceId": 7349309,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
