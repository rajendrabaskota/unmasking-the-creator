{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U datasets huggingface-hub\n",
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the notebook before proceeding further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:36.538970Z",
     "iopub.status.busy": "2024-01-07T11:56:36.538608Z",
     "iopub.status.idle": "2024-01-07T11:56:38.221743Z",
     "shell.execute_reply": "2024-01-07T11:56:38.220670Z",
     "shell.execute_reply.started": "2024-01-07T11:56:36.538935Z"
    }
   },
   "outputs": [],
   "source": [
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('<your_token>')\"\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:20:54.829013Z",
     "iopub.status.busy": "2024-01-12T16:20:54.828272Z",
     "iopub.status.idle": "2024-01-12T16:21:00.734478Z",
     "shell.execute_reply": "2024-01-12T16:21:00.733557Z",
     "shell.execute_reply.started": "2024-01-12T16:20:54.828972Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torchvision import transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run any of the below three sections then move to the section **Loading CLIP:Vit-L/14**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1) Creating DataFrame Object for ProGAN Train Dataset**\n",
    "* Add the kaggle dataset: **ai-vs-human-generated-images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_names(path):\n",
    "    return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df(df, path, images):\n",
    "    for img_type, img_names in images.items():\n",
    "        new_row = []\n",
    "        new_row = [[path + img_type + '/' + img_name, int(img_type[0])] for img_name in img_names]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row, columns=[\"file_path\", \"label\"])], ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"file_path\": [],\n",
    "    \"label\": []\n",
    "}, dtype=int)\n",
    "\n",
    "folders = os.listdir(\"/kaggle/input/ai-vs-human-generated-images\")\n",
    "for folder in folders:\n",
    "    if collections.Counter(os.listdir(\"/kaggle/input/ai-vs-human-generated-images/\"+folder)) == collections.Counter(['0_real', '1_fake']):\n",
    "        real_images = fetch_image_names(\"/kaggle/input/ai-vs-human-generated-images/\"+folder+'/'+'0_real')\n",
    "        fake_images = fetch_image_names(\"/kaggle/input/ai-vs-human-generated-images/\"+folder+'/'+'1_fake')\n",
    "        path = folder + '/'\n",
    "        images = {'0_real': real_images, '1_fake': fake_images}\n",
    "        df = append_df(df, path, images)\n",
    "    else:\n",
    "        for sub_folder in os.listdir(\"/kaggle/input/ai-vs-human-generated-images/\"+folder):\n",
    "            real_images = fetch_image_names(\"/kaggle/input/ai-vs-human-generated-images/\"+folder+'/'+sub_folder+'/'+'0_real')\n",
    "            fake_images = fetch_image_names(\"/kaggle/input/ai-vs-human-generated-images/\"+folder+'/'+sub_folder+'/'+'1_fake')\n",
    "            path = folder + '/' + sub_folder + '/'\n",
    "            images = {'0_real': real_images, '1_fake': fake_images}\n",
    "            df = append_df(df, path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2) Creating DataFrame Object for GAN Test Dataset**\n",
    "* Add the kaggle dataset: **GANs-dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_names(path):\n",
    "    return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df(df, path, images):\n",
    "    for img_type, img_names in images.items():\n",
    "        new_row = []\n",
    "        new_row = [[path + img_type + '/' + img_name, int(img_type[0])] for img_name in img_names]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row, columns=[\"file_path\", \"label\"])], ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"file_path\": [],\n",
    "    \"label\": []\n",
    "}, dtype=int)\n",
    "\n",
    "folders = os.listdir(\"/kaggle/input/progan-fake-dataset\")\n",
    "for folder in folders:\n",
    "    if collections.Counter(os.listdir(\"/kaggle/input/progan-fake-dataset/\"+folder)) == collections.Counter(['0_real', '1_fake']):\n",
    "        real_images = fetch_image_names(\"/kaggle/input/progan-fake-dataset/\"+folder+'/'+'0_real')\n",
    "        fake_images = fetch_image_names(\"/kaggle/input/progan-fake-dataset/\"+folder+'/'+'1_fake')\n",
    "        path = folder + '/'\n",
    "        images = {'0_real': real_images, '1_fake': fake_images}\n",
    "        df = append_df(df, path, images)\n",
    "    else:\n",
    "        for sub_folder in os.listdir(\"/kaggle/input/progan-fake-dataset/\"+folder):\n",
    "            real_images = fetch_image_names(\"/kaggle/input/progan-fake-dataset/\"+folder+'/'+sub_folder+'/'+'0_real')\n",
    "            fake_images = fetch_image_names(\"/kaggle/input/progan-fake-dataset/\"+folder+'/'+sub_folder+'/'+'1_fake')\n",
    "            path = folder + '/' + sub_folder + '/'\n",
    "            images = {'0_real': real_images, '1_fake': fake_images}\n",
    "            df = append_df(df, path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3) Creating DataFrame Object for Diffusion Test Dataset**\n",
    "* Add the kaggle dataset: **Diffusion-datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:51.419105Z",
     "iopub.status.busy": "2024-01-07T11:56:51.418657Z",
     "iopub.status.idle": "2024-01-07T11:56:51.423699Z",
     "shell.execute_reply": "2024-01-07T11:56:51.422726Z",
     "shell.execute_reply.started": "2024-01-07T11:56:51.419078Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_image_names(path):\n",
    "    return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:51.425720Z",
     "iopub.status.busy": "2024-01-07T11:56:51.425040Z",
     "iopub.status.idle": "2024-01-07T11:56:51.438184Z",
     "shell.execute_reply": "2024-01-07T11:56:51.437272Z",
     "shell.execute_reply.started": "2024-01-07T11:56:51.425683Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_df(df, path, images):\n",
    "    for img_type, img_names in images.items():\n",
    "        new_row = []\n",
    "        new_row = [[path + img_type + '/' + img_name, int(img_type[0])] for img_name in img_names]\n",
    "        df = pd.concat([df, pd.DataFrame(new_row, columns=[\"file_path\", \"label\"])], ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:56:54.010537Z",
     "iopub.status.busy": "2024-01-07T11:56:54.010171Z",
     "iopub.status.idle": "2024-01-07T11:56:55.175876Z",
     "shell.execute_reply": "2024-01-07T11:56:55.175050Z",
     "shell.execute_reply.started": "2024-01-07T11:56:54.010507Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"file_path\": [],\n",
    "    \"label\": []\n",
    "}, dtype=int)\n",
    "\n",
    "base_dir = \"/kaggle/input/diffusion-datasets/diffusion_datasets/\"\n",
    "folders = os.listdir(base_dir)\n",
    "for folder in folders:\n",
    "    if collections.Counter(os.listdir(base_dir + folder)) == collections.Counter(['1_fake']):\n",
    "        fake_images = fetch_image_names(base_dir + folder+'/'+'1_fake')\n",
    "        path = folder + '/'\n",
    "        images = {'1_fake': fake_images}\n",
    "        df = append_df(df, path, images)\n",
    "    else:\n",
    "        real_images = fetch_image_names(base_dir + folder+'/'+'0_real')\n",
    "        path = folder + '/'\n",
    "        images = {'0_real': real_images}\n",
    "        df = append_df(df, path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading CLIP:Vit-L/14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:33.468870Z",
     "iopub.status.busy": "2024-01-07T11:57:33.468515Z",
     "iopub.status.idle": "2024-01-07T11:57:52.526401Z",
     "shell.execute_reply": "2024-01-07T11:57:52.525230Z",
     "shell.execute_reply.started": "2024-01-07T11:57:33.468842Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:52.528787Z",
     "iopub.status.busy": "2024-01-07T11:57:52.528153Z",
     "iopub.status.idle": "2024-01-07T11:57:52.539046Z",
     "shell.execute_reply": "2024-01-07T11:57:52.537781Z",
     "shell.execute_reply.started": "2024-01-07T11:57:52.528756Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(base_dir + self.x.iloc[idx]['file_path']).resize((256, 256))\n",
    "        image = convert_tensor(image)\n",
    "        \n",
    "        if not image.shape[0] == 3:\n",
    "            print(f\"yes at index {idx}\")\n",
    "            image = image.repeat(3, 1, 1)\n",
    "            \n",
    "        return idx, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:52.540538Z",
     "iopub.status.busy": "2024-01-07T11:57:52.540220Z",
     "iopub.status.idle": "2024-01-07T11:57:56.821295Z",
     "shell.execute_reply": "2024-01-07T11:57:56.820083Z",
     "shell.execute_reply.started": "2024-01-07T11:57:52.540513Z"
    }
   },
   "outputs": [],
   "source": [
    "df['img_embed'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T11:57:56.824605Z",
     "iopub.status.busy": "2024-01-07T11:57:56.824003Z",
     "iopub.status.idle": "2024-01-07T11:57:56.906548Z",
     "shell.execute_reply": "2024-01-07T11:57:56.905645Z",
     "shell.execute_reply.started": "2024-01-07T11:57:56.824576Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset=CustomDataset(df),\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Generating Feature Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(dataloader):\n",
    "    images = data*255\n",
    "    inputs = processor(text='nothing', images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    outputs = outputs['image_embeds'].tolist()\n",
    "    idx = idx.tolist()\n",
    "    df['img_embed'].iloc[idx] = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Storing Generated Feature Space on the Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T12:12:23.764852Z",
     "iopub.status.busy": "2024-01-07T12:12:23.764117Z",
     "iopub.status.idle": "2024-01-07T12:12:24.993071Z",
     "shell.execute_reply": "2024-01-07T12:12:24.992119Z",
     "shell.execute_reply.started": "2024-01-07T12:12:23.764820Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T12:12:36.167059Z",
     "iopub.status.busy": "2024-01-07T12:12:36.164852Z",
     "iopub.status.idle": "2024-01-07T12:12:43.183077Z",
     "shell.execute_reply": "2024-01-07T12:12:43.182107Z",
     "shell.execute_reply.started": "2024-01-07T12:12:36.167020Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"<dataset_name>\", split=\"<train/test>\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4267723,
     "sourceId": 7349309,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
