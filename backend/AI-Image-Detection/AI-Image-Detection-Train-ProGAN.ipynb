{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U datasets huggingface-hub\n",
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart the kernel before proceeding further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_score, recall_score\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Training is done using only ProGAN images.\n",
    "* ## Testing is done on GAN and Diffusion-generated images.\n",
    "* ## Below two sections show the training process.\n",
    "* ## SVM and Neural Network are trained respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1) Training using SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Train Dataset with CLIP Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"rajendrabaskota/progan-train-dataset-all\", split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_dataset['img_embed'])\n",
    "y = np.array(train_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Test Datasets with CLIP Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_diffusion = load_dataset(\"rajendrabaskota/diffusion-test-dataset\", split=\"test\")\n",
    "dataset_gan = load_dataset(\"rajendrabaskota/gan-test-dataset\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gan = np.array(dataset_gan['img_embed'])\n",
    "X_diffusion = np.array(dataset_diffusion['img_embed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=0.05, verbose=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('image_detection.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gan = clf.predict(X_gan)\n",
    "y_pred_diffusion = clf.predict(X_diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan = Dataset.to_pandas(dataset_gan)\n",
    "df_diffusion = Dataset.to_pandas(dataset_diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_model(x):\n",
    "    match = re.match(r'^([^/]+)', x)\n",
    "\n",
    "    if match:\n",
    "        result = match.group(1)\n",
    "    else:\n",
    "        result = ''\n",
    "        \n",
    "    return result\n",
    "\n",
    "df_gan['model'] = df_gan['file_path'].apply(lambda x: identify_model(x))\n",
    "df_diffusion['model'] = df_diffusion['file_path'].apply(lambda x: identify_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan['y_pred'] = y_pred_gan\n",
    "df_diffusion['y_pred'] = y_pred_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_models = df_gan['model'].unique().tolist()\n",
    "diffusion_models = df_diffusion['model'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_gan, df_diffusion], ignore_index=True)\n",
    "models = df['model'].unique().tolist()\n",
    "models.remove('imagenet')\n",
    "models.remove('laion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'model': [],\n",
    "                       'accuracy': [],\n",
    "                       'f1_score': []\n",
    "                       })\n",
    "\n",
    "for model in models:\n",
    "    temp = df[df['model']==model]\n",
    "    if model in diffusion_models:\n",
    "        if model == 'guided':\n",
    "            temp = pd.concat([temp, df[df['model']=='imagenet']], ignore_index=True)\n",
    "        else:\n",
    "            temp = pd.concat([temp, df[df['model']=='laion']], ignore_index=True)\n",
    "    \n",
    "    y = temp['label']\n",
    "    y_pred = temp['y_pred']\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    f1 = sklearn.metrics.f1_score(y, y_pred, average='macro')\n",
    "    \n",
    "    results = pd.concat([results, pd.DataFrame([[model, acc, f1]], columns=['model', 'accuracy', 'f1_score'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results-svm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2) Training using Logistic Regression and Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:08:00.881041Z",
     "iopub.status.busy": "2024-01-26T09:08:00.880135Z",
     "iopub.status.idle": "2024-01-26T09:11:07.532743Z",
     "shell.execute_reply": "2024-01-26T09:11:07.531795Z",
     "shell.execute_reply.started": "2024-01-26T09:08:00.881008Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"rajendrabaskota/progan-train-dataset-all\", split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:11:42.664495Z",
     "iopub.status.busy": "2024-01-26T09:11:42.664161Z",
     "iopub.status.idle": "2024-01-26T09:12:07.123041Z",
     "shell.execute_reply": "2024-01-26T09:12:07.122113Z",
     "shell.execute_reply.started": "2024-01-26T09:11:42.664470Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_diffusion = load_dataset(\"rajendrabaskota/diffusion-test-dataset\", split=\"test\")\n",
    "dataset_gan = load_dataset(\"rajendrabaskota/gan-test-dataset\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Features into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T10:26:23.144831Z",
     "iopub.status.busy": "2024-01-26T10:26:23.143846Z",
     "iopub.status.idle": "2024-01-26T10:26:29.942239Z",
     "shell.execute_reply": "2024-01-26T10:26:29.941385Z",
     "shell.execute_reply.started": "2024-01-26T10:26:23.144787Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.tensor(train_dataset['img_embed']).to(device)\n",
    "y = torch.tensor(train_dataset['label'], dtype=torch.float32).to(device)\n",
    "y = torch.reshape(y, (y.shape[0], 1))\n",
    "\n",
    "X_gan = torch.tensor(dataset_gan['img_embed']).to(device)\n",
    "# y_gan = torch.tensor(dataset_gan['label']).to(device)\n",
    "X_diffusion = torch.tensor(dataset_diffusion['img_embed']).to(device)\n",
    "# y_diffusion = torch.tensor(dataset_diffusion['label']).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.02\n",
    "test_n = int(X.shape[0]*test_ratio)\n",
    "X_train = X[:-test_n]\n",
    "y_train = y[:-test_n]\n",
    "X_test = X[-test_n:]\n",
    "y_test = y[-test_n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SGDClassifier(loss='log_loss', max_iter=1000)\n",
    "# # clf.fit(X, y)\n",
    "# clf.partial_fit(X, y, classes=np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_gan = clf.predict(X_gan)\n",
    "# y_pred_diffusion = clf.predict(X_diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T10:29:02.052591Z",
     "iopub.status.busy": "2024-01-26T10:29:02.052215Z",
     "iopub.status.idle": "2024-01-26T10:29:02.059989Z",
     "shell.execute_reply": "2024-01-26T10:29:02.059020Z",
     "shell.execute_reply.started": "2024-01-26T10:29:02.052560Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_units, hidden_units, output_units):\n",
    "        super(NN, self).__init__()\n",
    "        self.input_units = input_units\n",
    "        self.output_units = output_units\n",
    "        self.hidden_units = hidden_units\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(self.input_units, self.hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(self.hidden_units, self.output_units)\n",
    "        )\n",
    "        \n",
    "#         self.network = nn.Linear(self.input_units, self.output_units)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        logits = self.network(x)\n",
    "        probs = F.sigmoid(logits)\n",
    "        \n",
    "        if not y == None:\n",
    "            loss = F.binary_cross_entropy(probs, y)\n",
    "        else:\n",
    "            loss = None\n",
    "        \n",
    "        return probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T10:29:02.956199Z",
     "iopub.status.busy": "2024-01-26T10:29:02.955461Z",
     "iopub.status.idle": "2024-01-26T10:29:02.963615Z",
     "shell.execute_reply": "2024-01-26T10:29:02.962541Z",
     "shell.execute_reply.started": "2024-01-26T10:29:02.956169Z"
    }
   },
   "outputs": [],
   "source": [
    "input_units = len(train_dataset[0]['img_embed']) # 768\n",
    "hidden_units = 100\n",
    "output_units = 1 # binary classification\n",
    "learning_rate = 0.03\n",
    "\n",
    "clf_nn = NN(input_units, hidden_units, output_units).to(device)\n",
    "optimizer = torch.optim.Adam(clf_nn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creading a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset=CustomDataset(X_train, y_train),\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T10:27:01.516724Z",
     "iopub.status.busy": "2024-01-26T10:27:01.515894Z",
     "iopub.status.idle": "2024-01-26T10:27:01.521835Z",
     "shell.execute_reply": "2024-01-26T10:27:01.520900Z",
     "shell.execute_reply.started": "2024-01-26T10:27:01.516691Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lr_scheduling_rate = 0.1\n",
    "def lr_scheduling(learning_rate):\n",
    "    temp = deepcopy(optimizer.state_dict())\n",
    "    learning_rate = learning_rate * lr_scheduling_rate\n",
    "    temp['param_groups'][0]['lr'] = learning_rate\n",
    "    optimizer.load_state_dict(temp)\n",
    "    \n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2800\n",
    "eval_iters = 100\n",
    "progress_bar = tqdm(total=epochs, desc=\"Training\", dynamic_ncols=True)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "num_no_consecutive_improvement = 0\n",
    "\n",
    "clf_nn.train()\n",
    "for i in tqdm(range(epochs)):\n",
    "#     for X_train, y_train in dataloader:\n",
    "    probs, train_loss = clf_nn(X_train, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1)%eval_iters == 0:\n",
    "        clf_nn.eval()\n",
    "        with torch.no_grad():\n",
    "            probs, test_loss = clf_nn(X_test, y_test)\n",
    "            test_losses.append(test_loss.item())\n",
    "            \n",
    "            try:\n",
    "                if min(test_losses) <= test_loss:\n",
    "                    num_no_consecutive_improvement += 1\n",
    "                elif num_no_consecutive_improvement > 0:\n",
    "                    num_no_consecutive_improvement = 0\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        progress_bar.set_postfix({'Train Loss': train_loss.item(), 'Test Loss': test_loss.item()}, refresh=True)\n",
    "        clf_nn.train()\n",
    "        \n",
    "    if num_no_consecutive_improvement == 10:\n",
    "        learning_rate = lr_scheduling(learning_rate)\n",
    "        print(f\"Changed lr to {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
    "        num_no_consecutive_improvement = 0\n",
    "\n",
    "    progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:12.890223Z",
     "iopub.status.busy": "2024-01-26T09:50:12.889716Z",
     "iopub.status.idle": "2024-01-26T09:50:13.210860Z",
     "shell.execute_reply": "2024-01-26T09:50:13.209929Z",
     "shell.execute_reply.started": "2024-01-26T09:50:12.890189Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_values = range(0, epochs, eval_iters)\n",
    "plt.plot(x_values, test_losses, color='red')\n",
    "plt.plot(x_values, train_losses, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:20.726236Z",
     "iopub.status.busy": "2024-01-26T09:50:20.725354Z",
     "iopub.status.idle": "2024-01-26T09:50:20.732908Z",
     "shell.execute_reply": "2024-01-26T09:50:20.731916Z",
     "shell.execute_reply.started": "2024-01-26T09:50:20.726203Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_nn.eval()\n",
    "threshold = 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    probs_gan, _ = clf_nn(X_gan)\n",
    "    probs_gan = probs_gan.cpu().detach().numpy()\n",
    "    probs_diffusion, _ = clf_nn(X_diffusion)\n",
    "    probs_diffusion = probs_diffusion.cpu().detach().numpy()\n",
    "    y_pred_gan = (probs_gan > threshold)\n",
    "    y_pred_diffusion = (probs_diffusion > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:21.235331Z",
     "iopub.status.busy": "2024-01-26T09:50:21.234604Z",
     "iopub.status.idle": "2024-01-26T09:50:21.853088Z",
     "shell.execute_reply": "2024-01-26T09:50:21.852014Z",
     "shell.execute_reply.started": "2024-01-26T09:50:21.235296Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gan = Dataset.to_pandas(dataset_gan)\n",
    "df_diffusion = Dataset.to_pandas(dataset_diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:21.855574Z",
     "iopub.status.busy": "2024-01-26T09:50:21.854872Z",
     "iopub.status.idle": "2024-01-26T09:50:22.048576Z",
     "shell.execute_reply": "2024-01-26T09:50:22.047719Z",
     "shell.execute_reply.started": "2024-01-26T09:50:21.855537Z"
    }
   },
   "outputs": [],
   "source": [
    "def identify_model(x):\n",
    "    match = re.match(r'^([^/]+)', x)\n",
    "\n",
    "    if match:\n",
    "        result = match.group(1)\n",
    "    else:\n",
    "        result = ''\n",
    "        \n",
    "    return result\n",
    "\n",
    "df_gan['model'] = df_gan['file_path'].apply(lambda x: identify_model(x))\n",
    "df_diffusion['model'] = df_diffusion['file_path'].apply(lambda x: identify_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:23.793203Z",
     "iopub.status.busy": "2024-01-26T09:50:23.792539Z",
     "iopub.status.idle": "2024-01-26T09:50:23.800153Z",
     "shell.execute_reply": "2024-01-26T09:50:23.799196Z",
     "shell.execute_reply.started": "2024-01-26T09:50:23.793167Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gan['y_pred'] = y_pred_gan\n",
    "df_diffusion['y_pred'] = y_pred_diffusion\n",
    "\n",
    "df_gan['y_probs'] = probs_gan\n",
    "df_diffusion['y_probs'] = probs_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:24.170848Z",
     "iopub.status.busy": "2024-01-26T09:50:24.169649Z",
     "iopub.status.idle": "2024-01-26T09:50:24.185017Z",
     "shell.execute_reply": "2024-01-26T09:50:24.184096Z",
     "shell.execute_reply.started": "2024-01-26T09:50:24.170802Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_models = df_gan['model'].unique().tolist()\n",
    "diffusion_models = df_diffusion['model'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:24.534221Z",
     "iopub.status.busy": "2024-01-26T09:50:24.533860Z",
     "iopub.status.idle": "2024-01-26T09:50:24.566096Z",
     "shell.execute_reply": "2024-01-26T09:50:24.565113Z",
     "shell.execute_reply.started": "2024-01-26T09:50:24.534192Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_gan, df_diffusion], ignore_index=True)\n",
    "models = df['model'].unique().tolist()\n",
    "models.remove('imagenet')\n",
    "models.remove('laion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:27.504789Z",
     "iopub.status.busy": "2024-01-26T09:50:27.504402Z",
     "iopub.status.idle": "2024-01-26T09:50:28.218821Z",
     "shell.execute_reply": "2024-01-26T09:50:28.217850Z",
     "shell.execute_reply.started": "2024-01-26T09:50:27.504749Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'model': [],\n",
    "                        'average_precision': [],\n",
    "                       'accuracy': [],\n",
    "                       'f1_score': [],\n",
    "                        'precision': [],\n",
    "                        'recall': []\n",
    "                       })\n",
    "\n",
    "for model in models:\n",
    "    temp = df[df['model']==model]\n",
    "    if model in diffusion_models:\n",
    "        if model == 'guided':\n",
    "            temp = pd.concat([temp, df[df['model']=='imagenet']], ignore_index=True)\n",
    "        else:\n",
    "            temp = pd.concat([temp, df[df['model']=='laion']], ignore_index=True)\n",
    "    \n",
    "    y = temp['label']\n",
    "    y_pred = temp['y_pred']\n",
    "    y_scores = temp['y_probs']\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    f1 = sklearn.metrics.f1_score(y, y_pred, average='macro')\n",
    "    avg_precision = average_precision_score(y, y_scores, average=\"macro\")\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    \n",
    "    results = pd.concat([results, pd.DataFrame([[model, avg_precision, acc, f1, precision, recall]], columns=['model', 'average_precision', 'accuracy', 'f1_score', 'precision', 'recall'])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T09:50:29.670050Z",
     "iopub.status.busy": "2024-01-26T09:50:29.669226Z",
     "iopub.status.idle": "2024-01-26T09:50:29.687159Z",
     "shell.execute_reply": "2024-01-26T09:50:29.686263Z",
     "shell.execute_reply.started": "2024-01-26T09:50:29.670007Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T10:03:08.844518Z",
     "iopub.status.busy": "2024-01-26T10:03:08.843735Z",
     "iopub.status.idle": "2024-01-26T10:03:08.856348Z",
     "shell.execute_reply": "2024-01-26T10:03:08.855436Z",
     "shell.execute_reply.started": "2024-01-26T10:03:08.844481Z"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"nn-progan-results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-26T10:03:24.102507Z",
     "iopub.status.busy": "2024-01-26T10:03:24.102113Z",
     "iopub.status.idle": "2024-01-26T10:03:24.109264Z",
     "shell.execute_reply": "2024-01-26T10:03:24.108277Z",
     "shell.execute_reply.started": "2024-01-26T10:03:24.102476Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(r'nn-progan-720k-adm-lr-0.3-no-hidden-units-epochs-20k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4278403,
     "sourceId": 7364728,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
